{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmWcB5GDmQwlkbN4MDi26M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joshika-Mentor/AI-Query-Tube/blob/Jayashree/Query_Tube_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Query-Tube Project**"
      ],
      "metadata": {
        "id": "yxm8hOYz7l-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets Python to use Google APIs"
      ],
      "metadata": {
        "id": "_sMx6Fzg7sgj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykidZvc37gqd",
        "outputId": "abd70905-9e06-46e6-8081-9f163674ff6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (2.187.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.29.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.27.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "pip install google-api-python-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It installs a library that helps the computer understand the meaning of sentences."
      ],
      "metadata": {
        "id": "H7iSu45c_sps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y8YRjS6_ojh",
        "outputId": "33ee56d7-7623-4151-f7b2-bb26ac4ca29f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It installs a library that helps Python learn from data and make predictions."
      ],
      "metadata": {
        "id": "VVutGwLk_7V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d_qfwO4_2I6",
        "outputId": "9680b631-97f3-455d-92e9-5f862d5aad90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It installs a library that can read subtitles (captions) from YouTube videos."
      ],
      "metadata": {
        "id": "8UjWVDxMAEMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eAn6eAlAOHj",
        "outputId": "2686c0ad-7348-408e-badf-480ab4d03041"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.2.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2026.1.4)\n",
            "Downloading youtube_transcript_api-1.2.3-py3-none-any.whl (485 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/485.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m481.3/485.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.1/485.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It installs a tool that helps you create a simple web app for your Python program."
      ],
      "metadata": {
        "id": "zRVrVPOpz045"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6CVtfmmcdmD",
        "outputId": "75d88199-5c73-469e-8bb1-b6e9a4cb30e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It installs a library that helps Python work with data easily."
      ],
      "metadata": {
        "id": "392RjNi3z-qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spphd_7CcjeV",
        "outputId": "c4d11772-2e87-4e90-f01d-293503edb1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports pandas library\n",
        "#pd is just a short name\n",
        "import pandas as pd\n",
        "\n",
        "#Imports Gradio library\n",
        "#gr is short form\n",
        "import gradio as gr\n",
        "\n",
        "#Imports NumPy\n",
        "#np is short name\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Connects your Python code to Google services\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "#Fetches subtitles (captions) from YouTube videos\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "#Converts text → numbers (embeddings)\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "#Measures how similar two meanings are\n",
        "#Used to:\n",
        "#rank videos\n",
        "#find best match\n",
        "#semantic ranking\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI6o7OCaeaOm",
        "outputId": "7a1fc9ad-21ac-486f-e884-a4cbe9138d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "# Your YouTube Data API key\n",
        "# This key allows your program to access YouTube data\n",
        "# (like searching videos, getting titles, views, etc.)\n",
        "API_KEY = \"AIzaSyC1NUBYrAEe0oBm3rX71lZHG7Jz-o7HPOE\"\n",
        "\n",
        "# Create a YouTube API service object\n",
        "# \"youtube\" → service name\n",
        "# \"v3\" → YouTube Data API version\n",
        "# developerKey → your API key for authentication\n",
        "youtube = build(\n",
        "    \"youtube\",\n",
        "    \"v3\",\n",
        "    developerKey=API_KEY\n",
        ")\n"
      ],
      "metadata": {
        "id": "_73rbesUcoWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained sentence transformer model\n",
        "# This model converts text sentences into numerical vectors (embeddings)\n",
        "# so the computer can understand the meaning of the text\n",
        "\n",
        "# \"all-MiniLM-L6-v2\" → fast and lightweight AI model for semantic search\n",
        "# device=\"cpu\" → run the model on CPU (works on normal laptops)\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\",device=\"cpu\")"
      ],
      "metadata": {
        "id": "4wcdWaiYfNif",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "71d7b692275e4b8fa065d05663b2e8bd",
            "849326aa667048819de7acd3c3a7081e",
            "0cac64e4aca14964b4234626b64ca629",
            "332eab0477214984ad76af5c37bca07c",
            "c7931a23d5844b1d90d8df72f2e0f96a",
            "83c8ff4a2dae40bdb24dccf01db8ef1f",
            "ee47c437805c4b6e96650b40f6ab452a",
            "fc93db70b30c401c86b7a16703a31f8e",
            "696117fe1fe042dab52b490063e31318",
            "a1a7034acba04ff9bf6d62758be7905f",
            "6a3843ab4ed54b1da36e5f962c075276",
            "7402e11b01484cb5906e9debf797dd94",
            "d156e64902104854a25aa91cfb250648",
            "31ef04430f74472297c08a48e27efc23",
            "914d55a7f66d4ffead9625fd44a966c6",
            "aa3cb5736f2b409e8e54940226f214f7",
            "2e91a953af734d9fb0e3522d81bacb01",
            "c3acd43f6fca43b4bf8e3241dd277032",
            "68139168592e43ad8457df0f04061204",
            "0fe112eb9e634dfd917f28649579c21e",
            "1189fab860514e79ab1ffa3cacaef99c",
            "9da2afff3c054b46aac634bbbe346dce",
            "e3138b49e33c4e4cbdf37a3f315be82d",
            "d453c178445143258372a0aa1cb0b5cd",
            "41f43c0748854eb6b59698f6c82c08c6",
            "f2c4b1dd08194882956803cfc9c8d8d6",
            "1acf5da5dedd467cbc7743ee67e231fb",
            "866efe4c2b7d49cda5f0d5fc9fd8230b",
            "ade40fe2af1c47329ffcf32e30c32611",
            "13e087ed56274bbe8db4172b442f96a8",
            "4c862c66a3ec42658fd0d81916782a0f",
            "83ed41b3553b41a79527d6347fbc1463",
            "d9505310853442168580144802a68157",
            "eb70cf39e00c43708fefeb3fcc58f2c9",
            "269bd8bb892e4b6bbf5ea994de4455b9",
            "aa2b309c8d16468788f353df91c5d673",
            "bf73d3779b0042eeb255333be6430964",
            "a40b9147f7da4b969b2396b4edcfa144",
            "b815e625e12e418b81ffcb481a38b86f",
            "195ea03225cf401f9254b13f0ba2b657",
            "6712e7ad06594af2800ea30f42121fc9",
            "cdabe3541eb840f69b5016492cd86a0d",
            "a36621310c9d43d3ba527452adc08140",
            "28e384e41dad4a91985a7af0b935db5f",
            "15fe388a1c4b4c77bef149f17160632e",
            "9e0c145cd6e84995b7cc778e6a917fc5",
            "16a59e6570654471b127b39401585599",
            "35eb24da74a34a70b38ade0376f2b7dd",
            "894dfe7d9ba54a7e9d1fcba88c638863",
            "b6abf38a6dad4fb7912df0392700d5aa",
            "0c358eca514f411aa04eb6e4e9d0cc2e",
            "ee1843995f5d4b4aa40614dd60d15ddb",
            "311f67c6675a4ab99de98b6d46c9ea05",
            "8c2639589f934831ae2b1301ed614f22",
            "8eb148cedb1a4becaf51ad69f3473fbf",
            "95a637db066a40db9fa2df95e85dcee5",
            "4a5eb6ab7c29452ebef772b0037d6829",
            "60c21b7933374e4baaa6bae296acf856",
            "56be6a1166874911b968750f431d7312",
            "a8aad183d02449bc8bc698b0c88e8475",
            "ba8274f0ad1d47e38689cb0da914b504",
            "2a9a1d76edc34aa3b1ee5954cf0863e1",
            "6a5c98b3f3144415b5c19920ccb29cee",
            "f770fc318c574b9faaba398eebde2912",
            "2be3bcf3d719464faaee00c8ace0fdaa",
            "896d8e772aed4cf880c422c44f1edb7e",
            "b503d5bc775d49c491f8f5aaf0aa122d",
            "41a74456eefb4c1bbbb8eb00163cd121",
            "35a15915cd474dd0883af67b57a1536f",
            "708a9b8093fc44e4971e174ddbf17181",
            "afa9df07234d4ca2962b70c94c5f8348",
            "bf1905d9ffdf40c88b85b9199d3870c5",
            "944d0743fc5b45e0a7c166b041629a17",
            "edfba50c372e441799dac4e60195b2e8",
            "59c1372e9ec3424995c848f7aeef98ca",
            "8e5fcd05be8046ffbafa985c7a6ea39a",
            "ca02e269fb0a46f29b89be789fb87fa9",
            "0681be6377ab4eafb9be69a3a1f8b20e",
            "04b2afb154c64c2b978885afb9d800c1",
            "19bada8df05d483980b41b151a6e9bae",
            "fe10de00d2504133803b558e69ab400f",
            "32a4d066a3aa4fb6abc13d68d0d41c91",
            "ee920d05e62748cca3fc90fbc054fca8",
            "80480742e33d4751ade11103c755ddc0",
            "116b42c62ede40e1942c210c68bfe2ac",
            "64240b8098944853b661adaecad16dad",
            "5421616e155c454ca4ad6b3f9045b762",
            "1862bd393f584a5f93fa3a146ef7669d",
            "c619be2d18094577a50ac3db46f16050",
            "bf735561797a41da9abd0b2b4ff6861b",
            "a3fc12fae6184c1893fa5bf0c9f8f7f5",
            "0fdae73807df4afe94942e2239dfcf4f",
            "7ccb893627be4d0f8130fbf5f5693868",
            "8f3d84dbdb5346f8b6731924d729e038",
            "25b239526d3741f18cf46c6700bf75b5",
            "96996b56d1164635b28ecd6b1aeea86e",
            "e0774cb8c59b4595ad7d969c9df0ecad",
            "ade069e0cce045dd91e8cada96fa94b6",
            "c45f9a228f0d4550bd54b9299ef70225",
            "da5aed5e7e76410ba056f344ab57d85c",
            "b64b299db9b64076bea2b909205314d0",
            "5003df5862d04a7ca27482fdc6219e0e",
            "6509c0f90fbd40edb4ef027f0625be60",
            "d7cd508e9ef64d2eb30e9b9086b98b8a",
            "2bf29e04574649d9a2b509130bf3aa52",
            "6dcde46391584b0fa286cd4c502bb03b",
            "b3bb1cbabcc741f798528ecfe5b4b9c5",
            "97c1306e92564e16b839b3048aa613a5",
            "0a355ea5203d489b9b85a4889ff0b9ed",
            "0e1fe4fcf2a3401b81bd35d7090227f4",
            "862de35b31a54c1a91706f03678598a9",
            "92751020930344ffa13c05ff02fece8d",
            "0bdbfc6608f249e1916fd4e7cfbfba78",
            "9e78ebe5e6644b0a9d51f7d3225a842e",
            "94cf210521e84518846276e47f821d7c",
            "ecd89f02eb5d43758f70dd5bf9cbad1d",
            "369396f929c94fbe86eef9bdef98fabf",
            "938948020a4c448692f70f9b39ed8b00",
            "4ad518f9ffa0467380ac67402f33ce3e",
            "7f8627c0cbb94791ba5d16fb1ba9e8bd",
            "31f2740aa21d4d73842f4e9c9ad98ade"
          ]
        },
        "outputId": "08ed1557-d997-4136-da0b-1a02cc63a71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71d7b692275e4b8fa065d05663b2e8bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7402e11b01484cb5906e9debf797dd94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3138b49e33c4e4cbdf37a3f315be82d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb70cf39e00c43708fefeb3fcc58f2c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15fe388a1c4b4c77bef149f17160632e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95a637db066a40db9fa2df95e85dcee5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b503d5bc775d49c491f8f5aaf0aa122d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0681be6377ab4eafb9be69a3a1f8b20e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c619be2d18094577a50ac3db46f16050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da5aed5e7e76410ba056f344ab57d85c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "862de35b31a54c1a91706f03678598a9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get trending YouTube videos\n",
        "# max_results = number of videos to fetch (default is 10)\n",
        "def get_trending_videos(max_results=10):\n",
        "\n",
        "    # Create a request to YouTube API\n",
        "    # part → what data we want (title, description, views etc.)\n",
        "    # chart=\"mostPopular\" → fetch trending videos\n",
        "    # regionCode=\"IN\" → trending videos in India\n",
        "    # maxResults → how many videos to return\n",
        "    request = youtube.videos().list(\n",
        "        part=\"snippet,statistics\",\n",
        "        chart=\"mostPopular\",\n",
        "        regionCode=\"IN\",\n",
        "        maxResults=max_results\n",
        "    )\n",
        "\n",
        "    # Send the request to YouTube and get response data\n",
        "    response = request.execute()\n",
        "\n",
        "    # Empty list to store all video details\n",
        "    videos = []\n",
        "\n",
        "     # Loop through each video returned by YouTube\n",
        "    for item in response[\"items\"]:\n",
        "\n",
        "         # Store required video information in dictionary format\n",
        "         # unique video ID\n",
        "         # video title\n",
        "         # video description\n",
        "         # thumbnail image\n",
        "         # channel name\n",
        "         videos.append({\n",
        "            \"video_id\": item[\"id\"],\n",
        "            \"title\": item[\"snippet\"][\"title\"],\n",
        "            \"description\": item[\"snippet\"][\"description\"],\n",
        "            \"thumbnail\": item[\"snippet\"][\"thumbnails\"][\"high\"][\"url\"],\n",
        "            \"channel\": item[\"snippet\"][\"channelTitle\"]\n",
        "        })\n",
        "\n",
        "    # Return the list of trending videos\n",
        "    return videos"
      ],
      "metadata": {
        "id": "qH54ydlLfYe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to search YouTube videos based on user query\n",
        "# query → search text entered by user\n",
        "# max_results → number of videos to fetch (default 40)\n",
        "def youtube_search(query, max_results=40):\n",
        "\n",
        "    # Create a YouTube search request\n",
        "    # part=\"snippet\" → fetch title, description, thumbnail, channel name\n",
        "    # q=query → user search text\n",
        "    # type=\"video\" → return only videos (not channels or playlists)\n",
        "    # maxResults → limit number of results\n",
        "    request = youtube.search().list(\n",
        "        part=\"snippet\",\n",
        "        q=query,\n",
        "        type=\"video\",\n",
        "        maxResults=max_results\n",
        "    )\n",
        "\n",
        "    # Execute the request and get response from YouTube\n",
        "    response = request.execute()\n",
        "\n",
        "    # Empty list to store video details\n",
        "    videos = []\n",
        "\n",
        "    # Loop through all returned search results\n",
        "    for item in response.get(\"items\", []):\n",
        "\n",
        "        try:\n",
        "            # Add required video information into list\n",
        "            videos.append({\n",
        "                \"video_id\": item[\"id\"][\"videoId\"],        # unique video ID\n",
        "                \"title\": item[\"snippet\"][\"title\"],         # video title\n",
        "                \"description\": item[\"snippet\"].get(\"description\", \"\"),  # description (safe)\n",
        "                \"thumbnail\": item[\"snippet\"][\"thumbnails\"][\"high\"][\"url\"],  # thumbnail image\n",
        "                \"channel\": item[\"snippet\"][\"channelTitle\"] # channel name\n",
        "            })\n",
        "\n",
        "        # If any video has missing data, skip it\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Convert list of videos into pandas DataFrame (table format)\n",
        "    return pd.DataFrame(videos)\n"
      ],
      "metadata": {
        "id": "19q46Y_xcykH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store already fetched transcripts\n",
        "# This avoids downloading the same transcript again and again\n",
        "TRANSCRIPT_CACHE = {}\n",
        "\n",
        "\n",
        "# Function to get transcript of a YouTube video\n",
        "# video_id → unique ID of the YouTube video\n",
        "def get_transcript(video_id):\n",
        "\n",
        "    # If transcript is already stored in cache\n",
        "    # return it immediately (faster)\n",
        "    if video_id in TRANSCRIPT_CACHE:\n",
        "        return TRANSCRIPT_CACHE[video_id]\n",
        "\n",
        "    try:\n",
        "        # Fetch transcript (subtitles) from YouTube\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "\n",
        "        # Combine all subtitle lines into one long text\n",
        "        text = \" \".join([x[\"text\"] for x in transcript])\n",
        "\n",
        "    except Exception:\n",
        "        # If transcript is disabled or not available\n",
        "        text = \"Transcript not available\"\n",
        "\n",
        "    # Save transcript text in cache\n",
        "    TRANSCRIPT_CACHE[video_id] = text\n",
        "\n",
        "    # Return transcript text\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "4bXOEqJcfhDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to rank YouTube videos based on meaning (semantic search)\n",
        "# query → user search text\n",
        "# df → dataframe containing YouTube videos\n",
        "# top_k → number of best results to return\n",
        "def semantic_rank_df(query, df, top_k=5):\n",
        "\n",
        "    # Safety check:\n",
        "    # If dataframe is empty, return empty result\n",
        "    if df.empty:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Combine title and description into one text\n",
        "    # fillna(\"\") prevents errors if value is missing\n",
        "    texts = (\n",
        "        df[\"title\"].fillna(\"\") +\n",
        "        \" \" +\n",
        "        df[\"description\"].fillna(\"\")\n",
        "    ).tolist()\n",
        "\n",
        "    try:\n",
        "        # Convert all video texts into embeddings (numbers)\n",
        "        video_embeddings = model.encode(texts)\n",
        "\n",
        "        # Convert user search query into embedding\n",
        "        query_embedding = model.encode([query])\n",
        "\n",
        "        # Calculate similarity between query and all videos\n",
        "        scores = cosine_similarity(\n",
        "            query_embedding,\n",
        "            video_embeddings\n",
        "        )[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        # If embedding fails, print error and return empty dataframe\n",
        "        print(\"Embedding error:\", e)\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get indexes of highest similarity scores\n",
        "    # argsort → sorts indexes\n",
        "    # [::-1] → descending order\n",
        "    # [:top_k] → take top results only\n",
        "    top_idx = np.argsort(scores)[::-1][:top_k]\n",
        "\n",
        "    # Select top ranked videos from dataframe\n",
        "    results = df.iloc[top_idx][\n",
        "        [\"title\", \"video_id\", \"channel\"]\n",
        "    ].copy()\n",
        "\n",
        "    # Add similarity score column\n",
        "    results[\"score\"] = scores[top_idx]\n",
        "\n",
        "    # Return ranked videos\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "o0jxDqzCfi0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main AI YouTube search function\n",
        "# query → text entered by the user in search box\n",
        "def search_youtube_ai(query):\n",
        "\n",
        "    # Check if user entered nothing\n",
        "    if query is None or query.strip() == \"\":\n",
        "        return \"<h3>⚠ Please enter search text</h3>\", pd.DataFrame()\n",
        "\n",
        "    # Search YouTube videos using keyword search\n",
        "    df = youtube_search(query)\n",
        "\n",
        "    # If no videos are found\n",
        "    if df.empty:\n",
        "        return \"<h3>No videos found</h3>\", pd.DataFrame()\n",
        "\n",
        "    # Rank videos using semantic (AI meaning-based) search\n",
        "    ranked_df = semantic_rank_df(query, df)\n",
        "\n",
        "    # If semantic ranking fails\n",
        "    if ranked_df.empty:\n",
        "        return \"<h3>Semantic ranking failed</h3>\", pd.DataFrame()\n",
        "\n",
        "    # HTML string to display results nicely\n",
        "    html = \"\"\n",
        "\n",
        "    # Loop through top ranked videos\n",
        "    for _, row in ranked_df.iterrows():\n",
        "\n",
        "        # Get thumbnail URL of the video\n",
        "        thumb = df[df.video_id == row.video_id].iloc[0][\"thumbnail\"]\n",
        "\n",
        "        # Create HTML block for each video result\n",
        "        html += f\"\"\"\n",
        "        <div style=\"display:flex;margin-bottom:20px;\">\n",
        "            <img src=\"{thumb}\" width=\"300\"\n",
        "                 style=\"border-radius:12px;margin-right:15px;\">\n",
        "            <div>\n",
        "                <h3>{row.title}</h3>\n",
        "                <b>{row.channel}</b><br>\n",
        "                <b>Similarity:</b> {row.score:.4f}<br><br>\n",
        "                <a target=\"_blank\"\n",
        "                   href=\"https://www.youtube.com/watch?v={row.video_id}\">\n",
        "                   ▶ Watch on YouTube\n",
        "                </a>\n",
        "            </div>\n",
        "        </div>\n",
        "        <hr>\n",
        "        \"\"\"\n",
        "\n",
        "    # Return HTML output and ranked dataframe\n",
        "    return html, ranked_df\n"
      ],
      "metadata": {
        "id": "QIyeWWhwfwLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display trending YouTube videos page\n",
        "def trending_page():\n",
        "\n",
        "    # Get trending videos data from YouTube API\n",
        "    videos = get_trending_videos()\n",
        "\n",
        "    # HTML heading for trending section\n",
        "    html = \"<h2>🔥 Trending on YouTube</h2><br>\"\n",
        "\n",
        "    # Loop through each trending video\n",
        "    for v in videos:\n",
        "\n",
        "        # Create HTML block for each video\n",
        "        html += f\"\"\"\n",
        "        <div style=\"display:flex;margin-bottom:25px;\">\n",
        "\n",
        "            <!-- Video thumbnail -->\n",
        "            <img src=\"{v['thumbnail']}\" width=\"320\"\n",
        "                 style=\"border-radius:12px;margin-right:15px;\"/>\n",
        "\n",
        "            <div>\n",
        "                <!-- Video title -->\n",
        "                <h3>{v['title']}</h3>\n",
        "\n",
        "                <!-- Channel name -->\n",
        "                <p><b>{v['channel']}</b></p>\n",
        "\n",
        "                <!-- YouTube watch link -->\n",
        "                <a href=\"https://www.youtube.com/watch?v={v['video_id']}\"\n",
        "                   target=\"_blank\">\n",
        "                    ▶ Watch\n",
        "                </a>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <hr>\n",
        "        \"\"\"\n",
        "\n",
        "    # Return final HTML page\n",
        "    return html\n"
      ],
      "metadata": {
        "id": "AswMo0hvgKtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Gradio app using Blocks layout\n",
        "# theme=Soft → gives a clean and modern UI design\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "    # App title and description shown at the top\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # ▶ QueryTube — AI YouTube Search\n",
        "        **Search exactly like YouTube with AI semantic understanding**\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Text box where user enters search query\n",
        "    query = gr.Textbox(\n",
        "        placeholder=\"Search anything — python, cricket, motivation, news...\",\n",
        "        label=\"🔍 Search YouTube\"\n",
        "    )\n",
        "\n",
        "    # Button to start search\n",
        "    search_btn = gr.Button(\"Search\")\n",
        "\n",
        "    # HTML output area (used to display thumbnails and video cards)\n",
        "    html_output = gr.HTML()\n",
        "\n",
        "    # Table output to show structured data\n",
        "    table_output = gr.Dataframe(\n",
        "        headers=[\"Video ID\", \"Title\", \"Channel\", \"Transcript\"],\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    # When app loads, show trending videos automatically\n",
        "    demo.load(\n",
        "        trending_page,          # function to call\n",
        "        outputs=html_output     # where to display output\n",
        "    )\n",
        "\n",
        "    # When search button is clicked:\n",
        "    # - take input from textbox\n",
        "    # - run AI search function\n",
        "    # - show results in HTML and table\n",
        "    search_btn.click(\n",
        "        fn=search_youtube_ai,\n",
        "        inputs=query,\n",
        "        outputs=[html_output, table_output]\n",
        "    )\n",
        "\n",
        "\n",
        "# Launch the Gradio web app\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "9yQ5vF2vgUIm",
        "outputId": "7e2c323f-8afd-429d-8751-1bff625ef6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3100559579.py:3: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9e4786a38fb1597498.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9e4786a38fb1597498.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}